{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all packages successfully imported\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "## PACKAGE IMPORTING AND GLOBAL VARIABLE DEFINITION ########\n",
    "########################################################################################\n",
    "\n",
    "# v080, using continous fake data to give more physcial ressults\n",
    "# from 721, set bias=False for LSTM and MLP; LSMT layer =1 and no dropout # one layer LSTM may be enough\n",
    "# V0.7  Update: Use large hidden size; MSE as loss function; Based on V0.60\n",
    "# V0.6  Update: Type 3 has better performance than type 4\n",
    "# V0.51 Update: to run on the oscilloscope data\n",
    "# V0.40 Update: to combine different networks\n",
    "# V0.31 Update: tof changed to tensor format, which is a grammar improvement instead of bug fix\n",
    "# V0.32 Update: Use L2 regularization instead of drapout\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch    # for setting seed to make it reproducible\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt  # for plotting\n",
    "import matplotlib.mlab as mlab  # for plotting\n",
    "import struct  # for binary file reading\n",
    "import numpy as np\n",
    "import time  # for time recording\n",
    "import math  # for sqrt\n",
    "from pathlib import Path  # for the size of the binary file\n",
    "from scipy.stats import norm  # for gaussian fit\n",
    "import sys  # for parameter receiving\n",
    "import os  # for mkdir\n",
    "from progressbar import *\n",
    "\n",
    "print(\"all packages successfully imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all global vars generated\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "time_epoch = time.time()\n",
    "\n",
    "SEED=5  # reproducible\n",
    "DATA_VERSION = '0710_5'\n",
    "\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(SEED)\n",
    "SAMPLE_EPOCH = 1  # test every xx epochs to record mu, timeresolution, and loss\n",
    "\n",
    "EPOCHS = 3\n",
    "MODEL_VERSION = '800'\n",
    "\n",
    "WAVE_LENGTH = 120\n",
    "NCHANNEL = 8\n",
    "\n",
    "LR = 0.001 + 0.001*np.random.rand()\n",
    "LRD = 0.9 + 0.1*np.random.rand()\n",
    "HIDDEN_SIZE = 60 + int(10*np.random.rand())\n",
    "NUM_LSTM_LAYERS = 4 #+int(2*np.random.rand())\n",
    "BATCH_SIZE = 256\n",
    "DROP_OUT = 0.3\n",
    "WEIGHT_DECAY = 0.0004 + 0.0004*np.random.rand()  # lambda of L2 regularization\n",
    "\n",
    "print(\"all global vars generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes defined\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "## CLASS AND FUNCTIION DEFINITION ########\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "class Waveforms(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, testRate = 0.3, train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.train = train\n",
    "        self.file = open(root_dir, 'rb')\n",
    "        self.waveLength = WAVE_LENGTH\n",
    "        self.NChannel = NCHANNEL\n",
    "        self.NEvents = Path(self.root_dir).stat().st_size / \\\n",
    "            (self.waveLength*self.NChannel+1)/4\n",
    "        print('NEvents = ', self.NEvents)\n",
    "        self.testRaio = testRate\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return int(self.NEvents*(1.0-self.testRaio))\n",
    "        else:\n",
    "            return int(self.NEvents*self.testRaio)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            self.file.seek((index+int(self.NEvents*self.testRaio))\n",
    "                           * (self.NChannel*self.waveLength+1)*4, 0)\n",
    "        else:\n",
    "            self.file.seek((index)*(self.NChannel*self.waveLength+1)*4, 0)\n",
    "        data = self.file.read(self.waveLength*self.NChannel*4)\n",
    "        wave = struct.unpack(str(self.NChannel*self.waveLength)+'f', data)\n",
    "        wave_tensor = torch.tensor(wave, dtype=torch.float32).reshape(\n",
    "            self.NChannel, self.waveLength)#.t()\n",
    "        data = self.file.read(4)\n",
    "        tof = struct.unpack('f', data)\n",
    "        tof_tensor = torch.tensor(tof, dtype=torch.float32)\n",
    "        sample = {'waveform': wave_tensor, 'tof': tof_tensor}\n",
    "        return sample\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, common_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(input_size, input_size // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_size // 2, input_size // 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(input_size // 4, common_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ComNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=NCHANNEL+1,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_layers=NUM_LSTM_LAYERS,\n",
    "            batch_first=True,\n",
    "            bias=False,\n",
    "            dropout = DROP_OUT\n",
    "        )\n",
    "        self.out1 = nn.Linear(HIDDEN_SIZE, 1, bias=False)\n",
    "        self.magnifier1 = MLP(NCHANNEL*WAVE_LENGTH, WAVE_LENGTH) # N to one\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x.dim\n",
    "        extra1 = self.magnifier1(x.view(x.size(0),NCHANNEL*WAVE_LENGTH))\n",
    "        extra1 = extra1.unsqueeze(2)\n",
    "        x = torch.cat((x,extra1), 2)\n",
    "\n",
    "        lstm_out, (h_n, h_c) = self.lstm(x, None)\n",
    "        # lstm_out[:, -1, :] is the last lines of the input batches, since it's a many to one IO structure.\n",
    "        out = (self.out1(lstm_out[:, -1, :]))\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d( 8 ,256 ,120)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256*256, 1)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        #self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = x.view(-1, 16 * 5 * 5)\n",
    "        #x = self.fc1(x)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def testDataset(network, dataVersion, outputPrefix, input_prefix = \"./Codes/V0.70/Data/\"):\n",
    "\n",
    "    inputFileName = input_prefix+dataVersion+\".bin\"\n",
    "    testWaveformDataset = Waveforms(inputFileName, testRate = 1.0, train=False)\n",
    "    testData = DataLoader(testWaveformDataset,\n",
    "                          batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    residualTofList = []\n",
    "    predictedTofList = []\n",
    "    labelTofList = []\n",
    "    print(\"Test Data: \" + dataVersion)\n",
    "    mu=sigma=0\n",
    "    with torch.no_grad( ):\n",
    "        for index, batch_data in enumerate(testData):\n",
    "            input = Variable(batch_data['waveform'])#.cuda()\n",
    "            b_y = Variable(batch_data['tof']).squeeze()#.cuda().squeeze()\n",
    "            output = comNN(input).squeeze()\n",
    "            residualTofList.extend(\n",
    "                (output-b_y).cpu().detach().numpy().tolist())\n",
    "            predictedTofList.extend(output.cpu().detach().numpy().tolist())\n",
    "            labelTofList.extend(b_y.cpu().detach().numpy().tolist())\n",
    "\n",
    "    (mu, sigma) = norm.fit(residualTofList)\n",
    "    n, bins, patches = plt.hist(residualTofList, 100, range=(-1, 1), density=2)\n",
    "    # add a 'best fit' line\n",
    "    y = norm.pdf(bins, mu, sigma)\n",
    "    l = plt.plot(bins, y, 'r--', linewidth=2)\n",
    "    plt.xlabel('Tof residual [ns]')\n",
    "    plt.title(\n",
    "        r'$\\mathrm{Tof\\ residual:}\\ \\mu=%.3f ns,\\ \\sigma/\\sqrt{2}=%.3f ns$' % (mu, sigma/math.sqrt(2)))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outputPath + outputPrefix +\n",
    "                \"Test_\" + dataVersion + \".png\")\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def my_mse_loss(x, y, n): \n",
    "    return torch.mean(torch.pow(torch.abs(x - y), n))\n",
    "\n",
    "print(\"all classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace: C:/Users/x/OneDrive/CODING/ True\n",
      "workspace: C:/Users/x/OneDrive/CODING/ True\n",
      "fileName: C:/Users/x/OneDrive/CODING//data/0710_5.bin True\n",
      "outputPath: C:/Users/x/OneDrive/CODING/0710_5_800_Aug20th_v1/ True\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "## INPUT/OUTPUT PATH SETTING ########\n",
    "########################################################################################\n",
    "workspace = 'C:/Users/x/OneDrive/CODING/'\n",
    "print('workspace:',workspace,os.path.exists(workspace))\n",
    "fileName = workspace+\"/data/\"+DATA_VERSION+\".bin\"\n",
    "outputPath = workspace+DATA_VERSION+\"_\"+MODEL_VERSION+\"_Aug20th_v1/\"\n",
    "if os.path.exists(outputPath) == False:\n",
    "    os.mkdir(outputPath)\n",
    "outputPrefix = DATA_VERSION+\"_SEED\"+str(SEED).zfill(4) + \"_E\"+str(EPOCHS)\n",
    "\n",
    "if True:\n",
    "  print('workspace:',workspace,os.path.exists(workspace))\n",
    "  print('fileName:',fileName,os.path.exists(fileName))\n",
    "  print('outputPath:',outputPath,os.path.exists(outputPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "N/A% (0 of 3) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEvents =  10579.0\n",
      "NEvents =  10579.0\n",
      "CNN_Net(\n",
      "  (conv1): Conv1d(8, 256, kernel_size=(120,), stride=(1,))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=65536, out_features=1, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0012219931710897396\n",
      "    weight_decay: 0.0007674443631751687\n",
      ")\n",
      "Data: 0710_5; SEED = 5； Epochs = 3\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "256 256 1\n",
      "237 237 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (237) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-c481fe3ce5b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-9377ca0a592d>\u001b[0m in \u001b[0;36mmy_mse_loss\u001b[1;34m(x, y, n)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmy_mse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"all classes defined\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (237) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "## EXCUTION: Training ########\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "trainWaveformDataset = Waveforms(fileName, train=True)\n",
    "testWaveformDataset = Waveforms(fileName, train=False)\n",
    "trainData = DataLoader(trainWaveformDataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testData = DataLoader(testWaveformDataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "comNN = CNN_Net()\n",
    "\n",
    "use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速\n",
    "if use_gpu:\n",
    "    comNN = comNN.cuda()\n",
    "    \n",
    "\n",
    "print(comNN)\n",
    "\n",
    "optimizer = optim.Adam(comNN.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=LRD)\n",
    "print(optimizer)\n",
    "# loss_func = nn.MSELoss().cuda()\n",
    "loss_func = my_mse_loss\n",
    "\n",
    "testLoss_his = []\n",
    "trainLoss_his = []\n",
    "timeResolution_his = []\n",
    "mu_his = []\n",
    "residualTofList = []\n",
    "predictedTofList = []\n",
    "labelTofList = []\n",
    "\n",
    "print(\"Data: \" + DATA_VERSION + \"; SEED = \" + str(SEED)+\"； Epochs = \" + str(EPOCHS))\n",
    "progress = ProgressBar()\n",
    "for epoch in progress(range(EPOCHS)):\n",
    "    epoch_loss = 0  # for LR decay rate scheduler\n",
    "    for index, batch_data in enumerate(trainData):\n",
    "        input = Variable(batch_data['waveform']).squeeze()#.cuda()\n",
    "        b_y = Variable(batch_data['tof']).squeeze()#.cuda().squeeze()\n",
    "        # print(input.size())\n",
    "        output = comNN(input).squeeze()\n",
    "        print(len(output),len(b_y),\"1\")\n",
    "        loss = loss_func(output, b_y, 2)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.data.cpu().numpy()\n",
    "    scheduler.step(epoch_loss)\n",
    "\n",
    "    # to store the sigma, mu, loss\n",
    "    if (epoch) % SAMPLE_EPOCH == 0:\n",
    "        trainLoss_his.append(loss.data.cpu().numpy())\n",
    "        residualTofList.clear()\n",
    "        predictedTofList.clear()\n",
    "        labelTofList.clear()\n",
    "        for index, batch_data in enumerate(testData):\n",
    "            input = Variable(batch_data['waveform'])#.cuda().cuda()\n",
    "            b_y = Variable(batch_data['tof']).squeeze()#.cuda().cuda().squeeze()\n",
    "            output = comNN(input).squeeze()\n",
    "            loss = loss_func(output, b_y, 2)\n",
    "            residualTofList.extend(\n",
    "                (output-b_y).cpu().detach().numpy().tolist())\n",
    "            predictedTofList.extend(output.cpu().detach().numpy().tolist())\n",
    "            labelTofList.extend(b_y.cpu().detach().numpy().tolist())\n",
    "            # print('output length: ',output.cpu().detach().numpy().tolist().__len__())\n",
    "        # print('toflist length: ',tofList.__len__())\n",
    "        (mu, sigma) = norm.fit(residualTofList)\n",
    "        timeResolution_his.append(sigma/math.sqrt(2))\n",
    "        mu_his.append(mu)\n",
    "        testLoss_his.append(loss.data.cpu().numpy())\n",
    "\n",
    "\n",
    "# save model\n",
    "torch.save(comNN, outputPath+outputPrefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "## EXCUTION:Plotting ########\n",
    "########################################################################################\n",
    "time_start = time.time()\n",
    "plt.plot(testLoss_his, label='testLoss')\n",
    "plt.plot(trainLoss_his, label='trainLoss')\n",
    "plt.grid(True)\n",
    "# plt.ylim([0.01, 0.08])\n",
    "# plt.ylabel(\"MSE [ns^2]\")\n",
    "plt.title(\"Loss/MSE Vs Epochs\")\n",
    "plt.xlabel(\"sampled every \"+str(SAMPLE_EPOCH)+\" epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(outputPath+outputPrefix+\"_Loss.png\")\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(mu_his)\n",
    "plt.grid(True)\n",
    "plt.title(\"Average predicted ToF Vs Epochs\")\n",
    "plt.ylabel(\"Average of predicted ToF [ns]\")\n",
    "plt.ylim([-0.1, 0.1])\n",
    "plt.xlabel(\"sampled every \"+str(SAMPLE_EPOCH)+\" epochs\")\n",
    "plt.savefig(outputPath+outputPrefix+\"_Mu.png\")\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(timeResolution_his)\n",
    "plt.ylabel(\"Time Resolution [ns]\")\n",
    "plt.grid(True)\n",
    "plt.ylim([0.05, 0.30])\n",
    "plt.title(\"TimeResolution Vs Epochs\")\n",
    "plt.xlabel(\"sampled every \"+str(SAMPLE_EPOCH)+\" epochs\")\n",
    "plt.savefig(outputPath+outputPrefix+\"_TR.png\")\n",
    "plt.clf()\n",
    "\n",
    "(mu, sigma) = norm.fit(residualTofList)\n",
    "n, bins, patches = plt.hist(residualTofList, 100, range=(-1, 1), density=1)\n",
    "# add a 'best fit' line\n",
    "y = norm.pdf(bins, mu, sigma)\n",
    "l = plt.plot(bins, y, 'r--', linewidth=2)\n",
    "plt.xlabel('Tof residual [ns]')\n",
    "# plt.ylabel('Probability')\n",
    "plt.title(r'$\\mathrm{Tof\\ residual:}\\ \\mu=%.3f ns,\\ \\sigma/\\sqrt{2}=%.3f ns$' %(mu, sigma/math.sqrt(2)))\n",
    "plt.grid(True)\n",
    "plt.savefig(outputPath+outputPrefix+\"_TofHist.png\")\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
